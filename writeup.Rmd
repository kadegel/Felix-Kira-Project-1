---
title: "Project 1"
author: "Name: Kira Degelsmith\n Partner: Felix Lopez"
date: "`r Sys.Date()`"
output: 
  pdf_document:
    toc: true
    toc_depth: 3
---
```{r setup, include = FALSE}

#### Load necessary packages ####
packages <- c("knitr", "readr", "geosphere")

install_me <- packages[!(packages %in% installed.packages()[, "Package"])]
if (length(install_me)) install.packages(install_me)

library(knitr)
library(readr)
library(geosphere)
```

## Background
The World Health Organization has recently employed a new data science initiative, *CSIT-165*, that uses data science to characterize pandemic diseases. 
*CSIT-165* disseminates data driven analyses to global decision makers.

*CSIT-165* is a conglomerate comprised of two fabricated entities: *Global Health Union (GHU)* and *Private Diagnostic Laboratories (PDL)*. 
Your and your partner's role is to play a data scientist from one of these two entities.

## Data
> [2019 Novel Coronavirus COVID-19 (2019-nCoV) Data Repository by John Hopkins CSSE](https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series)  

```{r df_vars}
# Create data frames for deaths and confirmations from csv files
deaths_df <- readr::read_csv("time_series_covid19_deaths_global.csv")
confirmations_df <- readr::read_csv("time_series_covid19_confirmed_global.csv")
```

## Project Objectives

### Objective 1
```{r ob1}
#create variable to hold firts date
first_date <- colnames(confirmations_df)[5]  # "1/22/20"

# Find the region with the most confirmed cases on the first date
max_confirmations <- max(confirmations_df[[first_date]], na.rm = TRUE)
origin_confirm <- confirmations_df %>%
  filter(!!sym(first_date) == max_confirmations) %>%
  select(`Province/State`, `Country/Region`)

# Find the region with the most deaths on the first date
max_deaths <- max(deaths_df[[first_date]], na.rm = TRUE)
origin_death <- deaths_df %>%
  filter(!!sym(first_date) == max_deaths) %>%
  select(`Province/State`, `Country/Region`)

# Convert to character strings for better comparison
origin_confirm_str <- paste(origin_confirm$`Province/State`, origin_confirm$`Country/Region`, sep=", ")
origin_death_str <- paste(origin_death$`Province/State`, origin_death$`Country/Region`, sep=", ")

# Check if both values match using an if statement
if (all(origin_confirm_str %in% origin_death_str)) {
  print(paste("The origin of COVID-19 is:", origin_confirm_str))
} else {
  print("The origin is uncertain as the highest confirmations and deaths do not match exactly.")
}

# Print results
print(origin_confirm)
print(origin_death)

```

### Objective 2
```{r ob2}

```

### Objective 3
```{r ob3}

```

### Objective 4
```{r ob4}
# Create function to calculate risk scores
# Convert NaN values to 0, since they mean there were not any confirmations
risk_score <- function(deaths, confirmations)
{
  risk <- 100 * (deaths/confirmations)
  risk[is.nan(risk)] <- 0
  return(risk)
}

# Filter out cruise ships from the two data frames
deaths_no_cruise <- deaths_df[deaths_df$Lat != 0 & deaths_df$Long != 0
                              & !is.na(deaths_df$Lat)
                              & !is.na(deaths_df$Long),]
confirmations_no_cruise <- confirmations_df[confirmations_df$Lat != 0
                                            & confirmations_df$Long != 0
                                            & !is.na(confirmations_df$Lat)
                                            & !is.na(confirmations_df$Long),]

# Create a vector containing the most recent risk score for each area
current_deaths <- deaths_no_cruise[, ncol(deaths_no_cruise), drop=TRUE]
current_confirmations <- confirmations_no_cruise[, ncol(confirmations_no_cruise),
                                                 drop=TRUE]
current_risk_scores <- risk_score(current_deaths, current_confirmations)

# Find the index (which will correspond to the row) of the lowest risk score
# If more than one are the same, show the one with more confirmations
low_index <- which(current_risk_scores == min(current_risk_scores))
if(length(low_index) > 1)
{
  low_index <- which(current_confirmations == max(current_confirmations[low_index]))
}

# Find and display the area with the lowest risk score
cat("The area that currently has the lowest risk score is ", confirmations_no_cruise[low_index,1,drop=TRUE], ", ", confirmations_no_cruise[low_index,2,drop=TRUE], ", with a score of ", round(current_risk_scores[low_index],2), "%.", sep = "", fill = TRUE)

# Find the index (which will refer to the row) of the highest risk score
# If more than one are the same, show the one with more confirmations
high_index <- which(current_risk_scores == max(current_risk_scores))
if(length(high_index) > 1)
{
  high_index <- which(current_confirmations == max(current_confirmations[high_index]))
}

# Find and display the area with the highest risk score
cat("The area that currently has the highest risk score is ", confirmations_no_cruise[high_index,2,drop=TRUE], ", with a score of ", round(current_risk_scores[high_index],2), "%.", sep = "", fill = TRUE)

# Since the highest risk score is over 100%...
# Find the highest risk score which is less than or equal to 100%
risk_scores_adjusted <- ifelse(current_risk_scores > 100, NA, current_risk_scores)
high_index_adjusted <- which(risk_scores_adjusted == max(risk_scores_adjusted, na.rm=TRUE))
if(length(high_index_adjusted) > 1)
{
  high_index_adjusted <- which(current_confirmations == max(
    current_confirmations[high_index_adjusted], na.rm=TRUE))
}

# Find and display the area with the highest risk score <=100
cat("The area that currently has the highest risk score is ", confirmations_no_cruise[high_index_adjusted,2,drop=TRUE], ", with a score of ", round(current_risk_scores[high_index_adjusted],2), "%.", sep = "", fill = TRUE)

# Find global risk score
global_risk <- risk_score(sum(current_deaths), sum(current_confirmations))

# Compare global risk score to the highest and lowest risk areas
low_to_global <- global_risk - current_risk_scores[low_index]
high_to_global <- global_risk - current_risk_scores[high_index]
high_adj_to_global <- global_risk - current_risk_scores[high_index_adjusted]

# Display comparisons of high, low, and global risk scores
cat("The global risk score is currently ", round(global_risk,2), "%. The area that currently has", "the lowest risk score has a score that is ", round(low_to_global,2), "% lower", "than the global risk score. The area that currently has", "the highest risk score (<= 100%) has a score that is ", abs(round(high_adj_to_global,2)), "% higher than the global risk score.", sep = "", fill = TRUE)
```
#### Objective 4 Responses  
- Calculating metrics like risk scores for different areas of the world can be helpful for many reasons. Knowing the COVID-19 risk score for a certain area of the world can help researchers determine where risk is highest and lowest, and where resources may be most effective and beneficial if they are deciding on distribution locations. Additionally, tracking risk scores over time for different areas of the world can provide information about trends in risk scores over the years and also during different times of the year and how that varies from location to location.
- One limitation from calculating risk scores is that the risk score assumes that valid and accurate data has been reported. An example of this limitation is evident in the code chunk above. The highest risk score without any adjustment came out to be 600% in North Korea, since the most recent North Korean data shows 6 deaths but only 1 confirmed case. Since the risk score is over 100%, it is possible to decide that the data for North Korea is erroneous in some way, so to find the highest risk rate, you go to the highest rate that is less than or equal to 100%. This example with North Korea made it obvious to see that there was something going wrong with the data, but if the outcome didn't surpass 100%, it would be harder to see an error similar to this. Incorrect, incomplete, or otherwise erroneous data can cause problems when calculating metrics like risk scores, and it is important to take that into account when running analyses on data sets.

### Objective 5
```{r ob5, results='axis'}
# Create a function to create a new data frame with top 5 countries and sums for 
# deaths and confirmations
top_5_country_sums <- function(df)
{
  # Find all unique countries from the data set
  countries <- unique(df[, "Country/Region", drop=TRUE])
  
  # Create empty list to hold sum for each country
  sum_list <- list()
  
  # For loop to add death sum for each country to the list
  for(country in countries)
  {
    sum_list[[country]] <- sum(df[df[,2,drop=TRUE]==country,
                                  grep("[0-9]{1,2}/[0-9]{1,2}/[0-9]{1,2}",
                                       colnames(df))])
  }
  
  # Create new data frame with countries and sums
  sums_df <- data.frame("Country"=countries, "Total"=unlist(sum_list))
  
  # Return df with only the top 5 countries
  return(sums_df[order(sums_df$Total, decreasing=TRUE),][1:5,])
}

# Create tables for the top 5 countries for deaths and confirmations
top_5_death <- top_5_country_sums(deaths_df)
knitr::kable(top_5_death, caption = "Total Deaths by Country: Top 5 Countries",
             row.names = FALSE)

top_5_confirmations <- top_5_country_sums(confirmations_df)
knitr::kable(top_5_confirmations,
             caption = "Total Confirmations by Country: Top 5 Countries",
             row.names = FALSE)
```

### GitHub Log
```{bash gitlog} 
git log --pretty=format:"%nSubject: %s%nAuthor: %aN%nDate: %aD%nBody: %b"
```





